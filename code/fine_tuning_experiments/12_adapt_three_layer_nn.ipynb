{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune a Three Layer Feedforward Neural Network on top of [paraphrase-mpnet-base-v2](https://huggingface.co/sentence-transformers/paraphrase-mpnet-base-v2)\n",
    "The weights of the pre-trained model are frozen.<br>\n",
    "Loss function used: `MultipleNegativesRankingLoss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/co21btech11001/.conda/envs/nlp_new/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import Any, List, Optional, Tuple#, Union\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.base.embeddings.base import BaseEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.embeddings.huggingface.base import HuggingFaceEmbedding\n",
    "from llama_index.embeddings.huggingface.pooling import Pooling\n",
    "from llama_index.finetuning import EmbeddingAdapterFinetuneEngine\n",
    "from llama_index.finetuning.embeddings.adapter_utils import BaseAdapter\n",
    "from llama_index.core.evaluation import EmbeddingQAFinetuneDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EmbeddingQAFinetuneDataset.from_json(\"data/train_dataset.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model and finetune for 32 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires torch dependency\n",
    "# from llama_index.embeddings.adapter.utils import TwoLayerNN\n",
    "from llama_index.core.embeddings import resolve_embed_model\n",
    "from llama_index.embeddings.adapter import AdapterEmbeddingModel\n",
    "from typing import Dict\n",
    "from utils import CustomNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/paraphrase-mpnet-base-v2\n",
      "Load pretrained SentenceTransformer: sentence-transformers/paraphrase-mpnet-base-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n"
     ]
    }
   ],
   "source": [
    "model_name = \"sentence-transformers/paraphrase-mpnet-base-v2\"\n",
    "base_embed_model = resolve_embed_model(f\"local:{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_model = CustomNN(\n",
    "    in_features = 768,\n",
    "    hidden_dim_1 = 1024,\n",
    "    hidden_dim_2 = 1024,\n",
    "    out_features = 768,\n",
    "    add_residual = True,\n",
    "    dropout = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.81it/s]\n"
     ]
    }
   ],
   "source": [
    "finetune_engine = EmbeddingAdapterFinetuneEngine(\n",
    "    train_dataset,\n",
    "    base_embed_model,\n",
    "    model_output_path=\"mpnet_big_ft_ep32\",\n",
    "    # model_checkpoint_path=\"model5_ck\",\n",
    "    adapter_model=adapter_model,\n",
    "    epochs=32,\n",
    "    verbose=False,\n",
    "    device=\"cuda\",\n",
    "    batch_size = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 61.52it/s]\n",
      "\n",
      "\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.20it/s]\n",
      "\n",
      "\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 109.14it/s]\n",
      "\n",
      "\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 57.55it/s]\n",
      "\n",
      "\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.01it/s]\n",
      "\n",
      "\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.13it/s]\n",
      "\n",
      "\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 101.06it/s]\n",
      "\n",
      "\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 93.27it/s]\n",
      "\n",
      "\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 101.84it/s]\n",
      "\n",
      "\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 105.49it/s]\n",
      "\n",
      "\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 106.24it/s]\n",
      "\n",
      "\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n",
      "\n",
      "\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 102.43it/s]\n",
      "\n",
      "\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 104.56it/s]\n",
      "\n",
      "\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 101.76it/s]\n",
      "\n",
      "\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.44it/s]\n",
      "\n",
      "\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 74.01it/s]\n",
      "\n",
      "\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 93.82it/s]\n",
      "\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "finetune_engine.finetune()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Takes 1044 MiB of GPU memory. Takes 23465s = 6h 31m 5s to train for 32 epochs.<br>\n",
    "Time per epoch: 733s = 12m 13s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
